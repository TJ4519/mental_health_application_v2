{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd \n",
    "import openai\n",
    "import huggingface \n",
    "from enum import Enum "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading mental elf data form hugginface (use hf cli access token for this project in the .env file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06896f38f9be4cdb8b5b3b97fe94c0f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/2.82k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tejas\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\mental-health-agent-XcAaYoBL-py3.11\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\tejas\\.cache\\huggingface\\hub\\datasets--Amod--mental_health_counseling_conversations. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cfea1e1a6db4050a716bb1e5d240145",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "combined_dataset.json:   0%|          | 0.00/4.79M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69a9a46e22854b43a1e7e00ebabbf0f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/3512 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "   # Load the dataset\n",
    "dataset = load_dataset(\"Amod/mental_health_counseling_conversations\")\n",
    "\n",
    "   # Access the train, validation, or test split if available\n",
    "train_data = dataset['train']  # or use 'validation', 'test' if those splits exist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "951f5a3b63844cc9a46b5c995270a935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/3512 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Take the loaded dataset object and save it into a the file called data \n",
    "train_data.save_to_disk('dataset')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the explicit role as natural language input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open AI API expects data in strcutured input format:\n",
    "# json\n",
    "\n",
    "# {\n",
    "#  \"messages\": [\n",
    "#    { \"role\": \"<role_name_1>\", \"content\": \"<custom_content>\" },\n",
    "#    { \"role\": \"<role_name_2>\", \"content\": \"<custom_content>\" },\n",
    "#    { \"role\": \"<role_name_3>\", \"content\": \"<custom_content>\" }\n",
    "#  ]\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Need enum classes for valid type inputs for role variable, and content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from typing import List, Dict\n",
    "\n",
    "# 1. Define an Enum class for RoleType\n",
    "class RoleType(Enum):\n",
    "    USER = \"user\"\n",
    "    SYSTEM = \"system\"\n",
    "    ASSISTANT = \"assistant\"\n",
    "\n",
    "# 2. Role class to represent a role and its associated content\n",
    "class Role(object):\n",
    "    def __init__(self, \n",
    "                 role_type:RoleType, \n",
    "                 content:str):\n",
    "        \"\"\"\n",
    "        Role class to represent a role and its associated content for a message\n",
    "        Args:\n",
    "            role_type (RoleType): The type of role\n",
    "            content (str): The content of the role\n",
    "        \"\"\"\n",
    "        self.role = role_type.value\n",
    "        self.content = content\n",
    "        self.value = {'role': self.role, 'content':self.content } \n",
    "\n",
    "\n",
    "# 3. Message class to combine roles and their contents in a structured message\n",
    "#  define the messsage class here\n",
    "class Message(object):\n",
    "    def __init__(self, user_content, system_content, assistant_content):\n",
    "        self.user_role = Role(role_type=RoleType.USER , content=user_content)\n",
    "        self.system_role = Role(role_type=RoleType.SYSTEM , content=system_content)\n",
    "        self.assistant_role = Role(role_type=RoleType.ASSISTANT, content=assistant_content)\n",
    "        self.message = {'messages':[self.system_role.value, self.user_role.value, self.assistant_role.value, ]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [{'role': 'system', 'content': 'You serve as a supportive and honest psychology and psychotherapy assistant. Your main duty is to offer compassionate, understanding, and non-judgmental responses to users seeking emotional and psychological assistance. Respond with empathy and exhibit active listening skills. Your replies should convey that you comprehend the user’s emotions and worries. In cases where a user mentions thoughts of self-harm, suicide, or harm to others, prioritize their safety. Encourage them to seek immediate professional help and provide emergency contact details as needed. It’s important to note that you are not a licensed medical professional. Refrain from diagnosing or prescribing treatments. Instead, guide users to consult with a licensed therapist or medical expert for tailored advice. Never store or disclose any personal information shared by users. Uphold their privacy at all times. Avoid taking sides or expressing personal viewpoints. Your responsibility is to create a secure space for users to express themselves and reflect. Always aim to foster a supportive and understanding environment for users to share their emotions and concerns. Above all, prioritize their well-being and safety.'}, {'role': 'user', 'content': 'I am really worried about one of my friends because I think he has major depression. He disagrees with me on that. He is shut off when it comes to talking to people and telling them how he really feels. He told me he feels empty inside and the only emotions he feels are anger and sadness. I suggested to him to get help and talk to his mom about it but he refuses.'}, {'role': 'assistant', 'content': \"First of all, I can tell that you really care about your friend and I think it's great that you are reaching out with your concern. It's hard to determine whether your friend would meet the criteria for an official diagnosis of depression without working with him, however, whether he does or not, therapy may be beneficial for him in working through these difficult feelings and relational challenges. Unfortunately, you can't make your friend get help. He will ultimately need to make that decision for himself, however, you can talk to him about your concerns and your hopes that he will reach out for help.\"}]}\n"
     ]
    }
   ],
   "source": [
    "context = train_data[152]['Context']\n",
    "response = train_data[152]['Response']\n",
    "system_content = \"You serve as a supportive and honest psychology and psychotherapy assistant. Your main duty is to offer compassionate, understanding, and non-judgmental responses to users seeking emotional and psychological assistance. Respond with empathy and exhibit active listening skills. Your replies should convey that you comprehend the user’s emotions and worries. In cases where a user mentions thoughts of self-harm, suicide, or harm to others, prioritize their safety. Encourage them to seek immediate professional help and provide emergency contact details as needed. It’s important to note that you are not a licensed medical professional. Refrain from diagnosing or prescribing treatments. Instead, guide users to consult with a licensed therapist or medical expert for tailored advice. Never store or disclose any personal information shared by users. Uphold their privacy at all times. Avoid taking sides or expressing personal viewpoints. Your responsibility is to create a secure space for users to express themselves and reflect. Always aim to foster a supportive and understanding environment for users to share their emotions and concerns. Above all, prioritize their well-being and safety.\"\n",
    "message_obj = Message(user_content=context, system_content=system_content, assistant_content = response )\n",
    "\n",
    "# Validate message object\n",
    "print(message_obj.message)\n",
    "\n",
    "#Note: I wonder if this can be simplified using a pydantic class?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling 100 context:response pairs for fine-tuning LLM\n",
    "#### Note: One could question why sample randomly? Wouldn't it be better to fine-tune using a properly defined cohort of conversations that pertain to certain classes of mental health problems? Maybe. It can be argued that most mental health problems and the appropriate response in natural language are highly corelated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Context': \"I'm a guy. If I don't like girls, nor do I like guys, does that mean I'm gay?\", 'Response': \"It doesn't sound like you are finding yourself attracted to anyone. \\xa0It could mean that you just haven't connected with anyone you find attractive, or that you are asexual - essentially not oriented toward anyone. \\xa0I would suggest doing some reading on asexuality and see if it connects to how you feel!\"}\n"
     ]
    }
   ],
   "source": [
    "# Sample 100 items from the 'train' split\n",
    "import random\n",
    "from loguru import logger\n",
    "sampled_dataset = random.choices(train_data, k=300)\n",
    "train_dataset = []\n",
    "\n",
    "# Print the sampled data to verify\n",
    "print(sampled_dataset[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [{'role': 'system', 'content': 'You serve as a supportive and honest psychology and psychotherapy assistant. Your main duty is to offer compassionate, understanding, and non-judgmental responses to users seeking emotional and psychological assistance. Respond with empathy and exhibit active listening skills. Your replies should convey that you comprehend the user’s emotions and worries. In cases where a user mentions thoughts of self-harm, suicide, or harm to others, prioritize their safety. Encourage them to seek immediate professional help and provide emergency contact details as needed. It’s important to note that you are not a licensed medical professional. Refrain from diagnosing or prescribing treatments. Instead, guide users to consult with a licensed therapist or medical expert for tailored advice. Never store or disclose any personal information shared by users. Uphold their privacy at all times. Avoid taking sides or expressing personal viewpoints. Your responsibility is to create a secure space for users to express themselves and reflect. Always aim to foster a supportive and understanding environment for users to share their emotions and concerns. Above all, prioritize their well-being and safety.'}, {'role': 'user', 'content': \"I'm a guy. If I don't like girls, nor do I like guys, does that mean I'm gay?\"}, {'role': 'assistant', 'content': \"It doesn't sound like you are finding yourself attracted to anyone. \\xa0It could mean that you just haven't connected with anyone you find attractive, or that you are asexual - essentially not oriented toward anyone. \\xa0I would suggest doing some reading on asexuality and see if it connects to how you feel!\"}]}\n"
     ]
    }
   ],
   "source": [
    "for row in sampled_dataset:\n",
    "    message_obj = Message(user_content=row['Context'], \n",
    "                          system_content=system_content, \n",
    "                          assistant_content=row['Response'])\n",
    "    \n",
    "    train_dataset.append(message_obj.message)\n",
    "\n",
    "# Print a sample message to verify\n",
    "print(train_dataset[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving training and validation in jsonl for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save data in JSONL format\n",
    "import json\n",
    "import os\n",
    "\n",
    "# The function 'save_to_jsonl' is defined to save a list of data into a JSON Lines (JSONL) file.\n",
    "# JSONL format stores each JSON object on a separate line, making it easy to process large datasets line-by-line.\n",
    "def save_to_jsonl(data, file_path):\n",
    "    # Ensure the directory for the file path exists, creating it if necessary.\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "    # Open the file in write mode. If the file does not exist, it will be created.\n",
    "    with open(file_path, 'w') as file:\n",
    "        # Iterate over each item in the data list.\n",
    "        for row in data:\n",
    "            # Convert the row (which is a dictionary) to a JSON string.\n",
    "            line = json.dumps(row)\n",
    "            # Write the JSON string to the file followed by a newline character.\n",
    "            file.write(line + '\\n')\n",
    "\n",
    "# Define the file paths where the training and validation data will be saved.\n",
    "training_data_path = 'src/fine_tuning_data_pairs/train.jsonl'\n",
    "validation_data_path = 'src/fine_tuning_data_pairs/validation.jsonl'\n",
    "\n",
    "# Save the training data to the specified file path in JSONL format.\n",
    "# The training data consists of all but the last 5 items in the 'train_dataset' list.\n",
    "# Save the training data to the specified file path in JSONL format.\n",
    "# The training data consists of all but the last 5 items in the 'train_dataset' list.\n",
    "# The iloc operation train_dataset[:-5] selects all items in the list except the last 5.\n",
    "save_to_jsonl(train_dataset[:-5], training_data_path)\n",
    "\n",
    "# Save the validation data to the specified file path in JSONL format.\n",
    "# The validation data consists of the last 5 items in the 'train_dataset' list.\n",
    "# The iloc operation train_dataset[-5:] selects the last 5 items in the list.\n",
    "save_to_jsonl(train_dataset[-5:], validation_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-Tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-03 17:39:59.020\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1mAPI key loaded successfully.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv('OPEN_AI_API_KEY')\n",
    "if api_key:\n",
    "    logger.info(\"API key loaded successfully.\")\n",
    "else:\n",
    "    raise logger.error(\"Failed to load API key.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open training in binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-03 17:40:00.857\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m18\u001b[0m - \u001b[1mTraining file ID: file-36oqg91UpmTYF7cqz6HwGf\u001b[0m\n",
      "\u001b[32m2024-12-03 17:40:01.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1mValidation file ID: file-K4FxUpHQPEVMHRoFaJxWwo\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "client = openai.OpenAI(api_key=api_key)\n",
    "import os\n",
    "# Open the files in binary mode to fix the TypeError\n",
    "training_data_path = open('src/fine_tuning_data_pairs/train.jsonl', 'rb')\n",
    "validation_data_path = open('src/fine_tuning_data_pairs/validation.jsonl', 'rb')\n",
    "\n",
    "# Here, we're uploading the training and validation data files to OpenAI's API for fine-tuning.\n",
    "# The `client.files.create` method is used to upload files. It takes two parameters: `file` and `purpose`.\n",
    "# The `file` parameter is the file object we want to upload, and `purpose` specifies the reason for uploading the file.\n",
    "# In this case, we're uploading for the purpose of 'fine-tune', which is a specific use case for the OpenAI API.\n",
    "\n",
    "# First, we upload the training data file.\n",
    "training_response = client.files.create(file=training_data_path, purpose='fine-tune')\n",
    "# The `training_response` variable now holds the response from the API after uploading the training data file.\n",
    "# We extract the unique identifier for the uploaded file from the response using `training_response.id`.\n",
    "training_file_id = training_response.id\n",
    "# We log the training file ID to keep track of it for future use.\n",
    "logger.info(f\"Training file ID: {training_file_id}\")\n",
    "\n",
    "# Next, we upload the validation data file following the same process.\n",
    "validation_response = client.files.create(file=validation_data_path, purpose='fine-tune')\n",
    "# The `validation_response` variable now holds the response from the API after uploading the validation data file.\n",
    "# We extract the unique identifier for the uploaded file from the response using `validation_response.id`.\n",
    "validation_file_id = validation_response.id\n",
    "# We log the validation file ID to keep track of it for future use.\n",
    "logger.info(f\"Validation file ID: {validation_file_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create fine-tuning job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-03 17:40:03.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m7\u001b[0m - \u001b[1mFine-tuning job created with ID: ftjob-dPCleM3A1IvvsjMzpQvhouS1\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-dPCleM3A1IvvsjMzpQvhouS1', created_at=1733247603, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-Ih9gu6VQMaX1uROaepvz1MZE', result_files=[], seed=114015339, status='validating_files', trained_tokens=None, training_file='file-36oqg91UpmTYF7cqz6HwGf', validation_file='file-K4FxUpHQPEVMHRoFaJxWwo', estimated_finish=None, integrations=[], user_provided_suffix='mental-health-assistant-2024-12-03_v2')\n"
     ]
    }
   ],
   "source": [
    "response = client.fine_tuning.jobs.create(training_file=training_file_id, \n",
    "                                          validation_file=validation_file_id, \n",
    "                                        #   model='gpt-4o-mini-2024-07-18' #fine-tuning with this model fails since OpenAI detects some content policy violations (mental elf) is really dangerous\n",
    "                                          model='gpt-3.5-turbo-0125', \n",
    "                                          suffix='mental-health-assistant-2024-12-03_v2'\n",
    "                                          )\n",
    "logger.info(f\"Fine-tuning job created with ID: {response.id}\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-dPCleM3A1IvvsjMzpQvhouS1', created_at=1733247603, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-Ih9gu6VQMaX1uROaepvz1MZE', result_files=[], seed=114015339, status='validating_files', trained_tokens=None, training_file='file-36oqg91UpmTYF7cqz6HwGf', validation_file='file-K4FxUpHQPEVMHRoFaJxWwo', estimated_finish=None, integrations=[], user_provided_suffix='mental-health-assistant-2024-12-03_v2')\n"
     ]
    }
   ],
   "source": [
    "#retrive the job status\n",
    "job_status = client.fine_tuning.jobs.retrieve(response.id)\n",
    "print(job_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ftjob-6s9YNdNyVHFHJ9M3Wm7qaiju\n",
    "# mental-health-assistant-2024-12-03\n",
    "# ft:gpt-3.5-turbo-0125:personal:mental-health-assistant-2024-12-03:AaPMIXsl\n",
    "\n",
    "# Metrics\n",
    "# Training loss\n",
    "# 2.7724\n",
    "# Full validation loss\n",
    "# 2.3029\n",
    "\n",
    "# Trained tokens = 295,191\n",
    "# Epochs = 3\n",
    "# Batch size = 1\n",
    "# LR Multiplier = 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "system_message = \"\"\"You serve as a supportive and honest psychology and psychotherapy assistant. \n",
    "Your main duty is to offer compassionate, understanding, and non-judgmental responses to users seeking emotional and psychological assistance. \n",
    "Respond with empathy and exhibit active listening skills. \n",
    "Your replies should convey that you comprehend the user's emotions and worries. \n",
    "In cases where a user mentions thoughts of self-harm, suicide, or harm to others, prioritize their safety. \n",
    "Encourage them to seek immediate professional help and provide emergency contact details as needed. \n",
    "It's important to note that you are not a licensed medical professional. \n",
    "Refrain from diagnosing or prescribing treatments. \n",
    "Instead, guide users to consult with a licensed therapist or medical expert for tailored advice. \n",
    "Never store or disclose any personal information shared by users. Uphold their privacy at all times. \n",
    "\n",
    "Your responsibility is to create a secure space for users to express themselves and reflect. \n",
    "Always aim to foster a supportive and understanding environment for users to share their emotions and concerns. \n",
    "Above all, prioritize their well-being and safety.\"\"\"\n",
    "messages = []\n",
    "\n",
    "messages.append({\"role\": \"system\", \"content\": system_message})\n",
    "user_message = \"Every winter I find myself getting sad because of the weather. I feel like killing myself.\"\n",
    "\n",
    "messages.append({\"role\": \"system\", \"content\": system_message})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# completion = client.chat.completions.create(\n",
    "#     model= \"gpt-4o-2024-08-06\",\n",
    "#     messages=messages\n",
    "# )\n",
    "# print(completion.choices[]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mental-health-agent-XcAaYoBL-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
