{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd \n",
    "import openai\n",
    "import huggingface \n",
    "from enum import Enum "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading mental elf data form hugginface (use hf cli access token for this project in the .env file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06896f38f9be4cdb8b5b3b97fe94c0f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/2.82k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tejas\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\mental-health-agent-XcAaYoBL-py3.11\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\tejas\\.cache\\huggingface\\hub\\datasets--Amod--mental_health_counseling_conversations. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cfea1e1a6db4050a716bb1e5d240145",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "combined_dataset.json:   0%|          | 0.00/4.79M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69a9a46e22854b43a1e7e00ebabbf0f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/3512 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "   # Load the dataset\n",
    "dataset = load_dataset(\"Amod/mental_health_counseling_conversations\")\n",
    "\n",
    "   # Access the train, validation, or test split if available\n",
    "train_data = dataset['train']  # or use 'validation', 'test' if those splits exist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "951f5a3b63844cc9a46b5c995270a935",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards):   0%|          | 0/3512 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Take the loaded dataset object and save it into a the file called data \n",
    "train_data.save_to_disk('dataset')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the explicit role as natural language input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open AI API expects data in strcutured input format:\n",
    "# json\n",
    "\n",
    "# {\n",
    "#  \"messages\": [\n",
    "#    { \"role\": \"<role_name_1>\", \"content\": \"<custom_content>\" },\n",
    "#    { \"role\": \"<role_name_2>\", \"content\": \"<custom_content>\" },\n",
    "#    { \"role\": \"<role_name_3>\", \"content\": \"<custom_content>\" }\n",
    "#  ]\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Need enum classes for valid type inputs for role variable, and content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from typing import List, Dict\n",
    "\n",
    "# 1. Define an Enum class for RoleType\n",
    "class RoleType(Enum):\n",
    "    USER = \"user\"\n",
    "    SYSTEM = \"system\"\n",
    "    ASSISTANT = \"assistant\"\n",
    "\n",
    "# 2. Role class to represent a role and its associated content\n",
    "class Role(object):\n",
    "    def __init__(self, \n",
    "                 role_type:RoleType, \n",
    "                 content:str):\n",
    "        \"\"\"\n",
    "        Role class to represent a role and its associated content for a message\n",
    "        Args:\n",
    "            role_type (RoleType): The type of role\n",
    "            content (str): The content of the role\n",
    "        \"\"\"\n",
    "        self.role = role_type.value\n",
    "        self.content = content\n",
    "        self.value = {'role': self.role, 'content':self.content } \n",
    "\n",
    "\n",
    "# 3. Message class to combine roles and their contents in a structured message\n",
    "#  define the messsage class here\n",
    "class Message(object):\n",
    "    def __init__(self, user_content, system_content, assistant_content):\n",
    "        self.user_role = Role(role_type=RoleType.USER , content=user_content)\n",
    "        self.system_role = Role(role_type=RoleType.SYSTEM , content=system_content)\n",
    "        self.assistant_role = Role(role_type=RoleType.ASSISTANT, content=assistant_content)\n",
    "        self.message = {'messages':[self.system_role.value, self.user_role.value, self.assistant_role.value, ]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [{'role': 'system', 'content': 'You serve as a supportive and honest psychology and psychotherapy assistant. Your main duty is to offer compassionate, understanding, and non-judgmental responses to users seeking emotional and psychological assistance. Respond with empathy and exhibit active listening skills. Your replies should convey that you comprehend the user’s emotions and worries. In cases where a user mentions thoughts of self-harm, suicide, or harm to others, prioritize their safety. Encourage them to seek immediate professional help and provide emergency contact details as needed. It’s important to note that you are not a licensed medical professional. Refrain from diagnosing or prescribing treatments. Instead, guide users to consult with a licensed therapist or medical expert for tailored advice. Never store or disclose any personal information shared by users. Uphold their privacy at all times. Avoid taking sides or expressing personal viewpoints. Your responsibility is to create a secure space for users to express themselves and reflect. Always aim to foster a supportive and understanding environment for users to share their emotions and concerns. Above all, prioritize their well-being and safety.'}, {'role': 'user', 'content': 'I am really worried about one of my friends because I think he has major depression. He disagrees with me on that. He is shut off when it comes to talking to people and telling them how he really feels. He told me he feels empty inside and the only emotions he feels are anger and sadness. I suggested to him to get help and talk to his mom about it but he refuses.'}, {'role': 'assistant', 'content': \"First of all, I can tell that you really care about your friend and I think it's great that you are reaching out with your concern. It's hard to determine whether your friend would meet the criteria for an official diagnosis of depression without working with him, however, whether he does or not, therapy may be beneficial for him in working through these difficult feelings and relational challenges. Unfortunately, you can't make your friend get help. He will ultimately need to make that decision for himself, however, you can talk to him about your concerns and your hopes that he will reach out for help.\"}]}\n"
     ]
    }
   ],
   "source": [
    "context = train_data[152]['Context']\n",
    "response = train_data[152]['Response']\n",
    "system_content = \"You serve as a supportive and honest psychology and psychotherapy assistant. Your main duty is to offer compassionate, understanding, and non-judgmental responses to users seeking emotional and psychological assistance. Respond with empathy and exhibit active listening skills. Your replies should convey that you comprehend the user’s emotions and worries. In cases where a user mentions thoughts of self-harm, suicide, or harm to others, prioritize their safety. Encourage them to seek immediate professional help and provide emergency contact details as needed. It’s important to note that you are not a licensed medical professional. Refrain from diagnosing or prescribing treatments. Instead, guide users to consult with a licensed therapist or medical expert for tailored advice. Never store or disclose any personal information shared by users. Uphold their privacy at all times. Avoid taking sides or expressing personal viewpoints. Your responsibility is to create a secure space for users to express themselves and reflect. Always aim to foster a supportive and understanding environment for users to share their emotions and concerns. Above all, prioritize their well-being and safety.\"\n",
    "message_obj = Message(user_content=context, system_content=system_content, assistant_content = response )\n",
    "\n",
    "# Validate message object\n",
    "print(message_obj.message)\n",
    "\n",
    "#Note: I wonder if this can be simplified using a pydantic class?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling 100 context:response pairs for fine-tuning LLM\n",
    "#### Note: One could question why sample randomly? Wouldn't it be better to fine-tune using a properly defined cohort of conversations that pertain to certain classes of mental health problems? Maybe. It can be argued that most mental health problems and the appropriate response in natural language are highly corelated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Context': \"My husband and I had our first threesome recently. Everyone was drinking and he was on her more then me.    He and I talked about it afterwards and it made me feel better, and now I'm craving more of it. But before it gets close to happening I get this empty feeling. Why am I feeling this way?\", 'Response': 'Hello there.\\xa0 As you have courageously explained your soulful dilemma. I can appreciate the complexity of this situation.\\xa0 You have identified some key factors that may be contributing to your sense of feeling \"empty\".\\xa0 One, is the ultimate goal here able to be acquired from this arrangement?\\xa0 Are you trying to have your fulfillment with another woman while in the presence of your husband but not with him \\'on her\\' as much or at all?\\xa0 Are you trying to ask him to be more passive participant?\\xa0 Perhaps be careful of not drinking too heavily... In the whole event, how do you want to feel intimate or connected ?\\xa0 Were you craving all along, him to really be all over you along with her?\\xa0 These are questions that arise; maybe not solutions.\\xa0 Its always good to be very clear with oneself of what is the ultimate target here... And always measure the potential danger..\\xa0 Peace - keith'}\n"
     ]
    }
   ],
   "source": [
    "# Sample 100 items from the 'train' split\n",
    "import random\n",
    "from loguru import logger\n",
    "sampled_dataset = random.choices(train_data, k=100)\n",
    "train_dataset = []\n",
    "\n",
    "# Print the sampled data to verify\n",
    "print(sampled_dataset[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [{'role': 'system', 'content': 'You serve as a supportive and honest psychology and psychotherapy assistant. Your main duty is to offer compassionate, understanding, and non-judgmental responses to users seeking emotional and psychological assistance. Respond with empathy and exhibit active listening skills. Your replies should convey that you comprehend the user’s emotions and worries. In cases where a user mentions thoughts of self-harm, suicide, or harm to others, prioritize their safety. Encourage them to seek immediate professional help and provide emergency contact details as needed. It’s important to note that you are not a licensed medical professional. Refrain from diagnosing or prescribing treatments. Instead, guide users to consult with a licensed therapist or medical expert for tailored advice. Never store or disclose any personal information shared by users. Uphold their privacy at all times. Avoid taking sides or expressing personal viewpoints. Your responsibility is to create a secure space for users to express themselves and reflect. Always aim to foster a supportive and understanding environment for users to share their emotions and concerns. Above all, prioritize their well-being and safety.'}, {'role': 'user', 'content': \"My husband and I had our first threesome recently. Everyone was drinking and he was on her more then me.    He and I talked about it afterwards and it made me feel better, and now I'm craving more of it. But before it gets close to happening I get this empty feeling. Why am I feeling this way?\"}, {'role': 'assistant', 'content': 'Hello there.\\xa0 As you have courageously explained your soulful dilemma. I can appreciate the complexity of this situation.\\xa0 You have identified some key factors that may be contributing to your sense of feeling \"empty\".\\xa0 One, is the ultimate goal here able to be acquired from this arrangement?\\xa0 Are you trying to have your fulfillment with another woman while in the presence of your husband but not with him \\'on her\\' as much or at all?\\xa0 Are you trying to ask him to be more passive participant?\\xa0 Perhaps be careful of not drinking too heavily... In the whole event, how do you want to feel intimate or connected ?\\xa0 Were you craving all along, him to really be all over you along with her?\\xa0 These are questions that arise; maybe not solutions.\\xa0 Its always good to be very clear with oneself of what is the ultimate target here... And always measure the potential danger..\\xa0 Peace - keith'}]}\n"
     ]
    }
   ],
   "source": [
    "for row in sampled_dataset:\n",
    "    message_obj = Message(user_content=row['Context'], \n",
    "                          system_content=system_content, \n",
    "                          assistant_content=row['Response'])\n",
    "    \n",
    "    train_dataset.append(message_obj.message)\n",
    "\n",
    "# Print a sample message to verify\n",
    "print(train_dataset[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving training and validation in jsonl for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to save data in JSONL format\n",
    "import json\n",
    "import os\n",
    "\n",
    "# The function 'save_to_jsonl' is defined to save a list of data into a JSON Lines (JSONL) file.\n",
    "# JSONL format stores each JSON object on a separate line, making it easy to process large datasets line-by-line.\n",
    "def save_to_jsonl(data, file_path):\n",
    "    # Ensure the directory for the file path exists, creating it if necessary.\n",
    "    os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "    # Open the file in write mode. If the file does not exist, it will be created.\n",
    "    with open(file_path, 'w') as file:\n",
    "        # Iterate over each item in the data list.\n",
    "        for row in data:\n",
    "            # Convert the row (which is a dictionary) to a JSON string.\n",
    "            line = json.dumps(row)\n",
    "            # Write the JSON string to the file followed by a newline character.\n",
    "            file.write(line + '\\n')\n",
    "\n",
    "# Define the file paths where the training and validation data will be saved.\n",
    "training_data_path = 'src/fine_tuning_data_pairs/train.jsonl'\n",
    "validation_data_path = 'src/fine_tuning_data_pairs/validation.jsonl'\n",
    "\n",
    "# Save the training data to the specified file path in JSONL format.\n",
    "# The training data consists of all but the last 5 items in the 'train_dataset' list.\n",
    "# Save the training data to the specified file path in JSONL format.\n",
    "# The training data consists of all but the last 5 items in the 'train_dataset' list.\n",
    "# The iloc operation train_dataset[:-5] selects all items in the list except the last 5.\n",
    "save_to_jsonl(train_dataset[:-5], training_data_path)\n",
    "\n",
    "# Save the validation data to the specified file path in JSONL format.\n",
    "# The validation data consists of the last 5 items in the 'train_dataset' list.\n",
    "# The iloc operation train_dataset[-5:] selects the last 5 items in the list.\n",
    "save_to_jsonl(train_dataset[-5:], validation_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-03 14:35:57.215\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1mAPI key loaded successfully.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv('OPEN_AI_API_KEY')\n",
    "if api_key:\n",
    "    logger.info(\"API key loaded successfully.\")\n",
    "else:\n",
    "    raise logger.error(\"Failed to load API key.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-12-03 14:43:48.781\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m13\u001b[0m - \u001b[1mTraining file ID: file-Jr4DVnHnGskXHkU2DgU57L\u001b[0m\n",
      "\u001b[32m2024-12-03 14:43:48.783\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m14\u001b[0m - \u001b[1mValidation file ID: file-Kua3s3aQsnMSGij1eYFp9U\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "client = openai.OpenAI(api_key=api_key)\n",
    "import os\n",
    "# Open the files in binary mode to fix the TypeError\n",
    "training_data_path = open('src/fine_tuning_data_pairs/train.jsonl', 'rb')\n",
    "validation_data_path = open('src/fine_tuning_data_pairs/validation.jsonl', 'rb')\n",
    "\n",
    "# Here, we're uploading the training and validation data files to OpenAI's API for fine-tuning.\n",
    "# The `client.files.create` method is used to upload files. It takes two parameters: `file` and `purpose`.\n",
    "# The `file` parameter is the file object we want to upload, and `purpose` specifies the reason for uploading the file.\n",
    "# In this case, we're uploading for the purpose of 'fine-tune', which is a specific use case for the OpenAI API.\n",
    "\n",
    "# First, we upload the training data file.\n",
    "training_response = client.files.create(file=training_data_path, purpose='fine-tune')\n",
    "# The `training_response` variable now holds the response from the API after uploading the training data file.\n",
    "# We extract the unique identifier for the uploaded file from the response using `training_response.id`.\n",
    "training_file_id = training_response.id\n",
    "# We log the training file ID to keep track of it for future use.\n",
    "logger.info(f\"Training file ID: {training_file_id}\")\n",
    "\n",
    "# Next, we upload the validation data file following the same process.\n",
    "validation_response = client.files.create(file=validation_data_path, purpose='fine-tune')\n",
    "# The `validation_response` variable now holds the response from the API after uploading the validation data file.\n",
    "# We extract the unique identifier for the uploaded file from the response using `validation_response.id`.\n",
    "validation_file_id = validation_response.id\n",
    "# We log the validation file ID to keep track of it for future use.\n",
    "logger.info(f\"Validation file ID: {validation_file_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': 'Model gpt-3.5-turbo-0613 is not available for fine-tuning or does not exist.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_available'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[115], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfine_tuning\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjobs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraining_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_file_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mvalidation_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_file_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                                        \u001b[49m\u001b[38;5;66;43;03m#   model='gpt-4o-mini-2024-07-18'\u001b[39;49;00m\n\u001b[0;32m      4\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgpt-3.5-turbo-0613\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mn_epochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43msuffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmental-health-assistant-2024-12-03\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFine-tuning job created with ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "File \u001b[1;32mc:\\Users\\tejas\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\mental-health-agent-XcAaYoBL-py3.11\\Lib\\site-packages\\openai\\resources\\fine_tuning\\jobs\\jobs.py:144\u001b[0m, in \u001b[0;36mJobs.create\u001b[1;34m(self, model, training_file, hyperparameters, integrations, seed, suffix, validation_file, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     78\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m     79\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m FineTuningJob:\n\u001b[0;32m     80\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;124;03m    Creates a fine-tuning job which begins the process of creating a new model from\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;124;03m    a given dataset.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/fine_tuning/jobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    147\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    149\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_file\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhyperparameters\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mintegrations\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mintegrations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msuffix\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalidation_file\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjob_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mJobCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFineTuningJob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tejas\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\mental-health-agent-XcAaYoBL-py3.11\\Lib\\site-packages\\openai\\_base_client.py:1280\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1267\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1268\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1275\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1276\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1277\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1278\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1279\u001b[0m     )\n\u001b[1;32m-> 1280\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\tejas\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\mental-health-agent-XcAaYoBL-py3.11\\Lib\\site-packages\\openai\\_base_client.py:957\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    954\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    955\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 957\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    961\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    962\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    963\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tejas\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\mental-health-agent-XcAaYoBL-py3.11\\Lib\\site-packages\\openai\\_base_client.py:1061\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1058\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1060\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1061\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1064\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1065\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1069\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1070\u001b[0m )\n",
      "\u001b[1;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': 'Model gpt-3.5-turbo-0613 is not available for fine-tuning or does not exist.', 'type': 'invalid_request_error', 'param': None, 'code': 'model_not_available'}}"
     ]
    }
   ],
   "source": [
    "response = client.fine_tuning.jobs.create(training_file=training_file_id, \n",
    "                                          validation_file=validation_file_id, \n",
    "                                        #   model='gpt-4o-mini-2024-07-18'\n",
    "                                          model='gpt-3.5-turbo-0125', \n",
    "                                          hyperparameters={'n_epochs': 3},\n",
    "                                          suffix='mental-health-assistant-2024-12-03'\n",
    "                                          )\n",
    "logger.info(f\"Fine-tuning job created with ID: {response.id}\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It turns out here is the message:\n",
    "# he job failed due to an invalid validation file. This training file was blocked by our moderation system because it contains too many examples that violate OpenAI's usage policies, or because it attempts to create model outputs that violate OpenAI's usage policies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content Policy moderation flags...using huggingface instead for opensource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "# from huggingface import transformers\n",
    "from transformers import Trainer, TrainingArguments, DistilBertForSequenceClassification\n",
    "\n",
    "# from transformers import Trainer, TrainingArguments, DistilBertForSequenceClassification\n",
    "\n",
    "#    # Load the model\n",
    "# model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "config = {\n",
    "       \"model_name\": \"distilbert-base-uncased\",\n",
    "       \"train_file\": \"raw_mental_health_dataset/combined_dataset.json\",\n",
    "       \"validation_file\": \"raw_mental_health_dataset/combined_dataset.json\",\n",
    "       \"output_dir\": \"output/\",\n",
    "       \"per_device_train_batch_size\": 8,\n",
    "       \"per_device_eval_batch_size\": 8,\n",
    "       \"num_train_epochs\": 3,\n",
    "       \"learning_rate\": 5e-5,\n",
    "       \"evaluation_strategy\": \"epoch\",\n",
    "       \"save_strategy\": \"epoch\",\n",
    "       \"logging_dir\": \"logs/\"\n",
    "   }\n",
    "\n",
    "with open('config.json', 'w') as f:\n",
    "    json.dump(config, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mental-health-agent-XcAaYoBL-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
